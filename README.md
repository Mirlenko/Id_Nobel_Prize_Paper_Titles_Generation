# Id_Nobel_Prize_Paper_Titles_Generation
## Solution for ODS (ods.ai) Hackaton (3-10.10.2020) Id Nobel Prize Paper Titles Generation

В рамках Хакатона, организованного [ODS](https://ods.ai/) 3-10 октября 2020 было предложено следующее решение к следующей задаче:
реализовать генератор тем [Шнобелевской премии](https://www.improbable.com/).

### Как использовать:
* В выбранную директорию помещается скриптовый файл (ig_nobel.py), файл c названиями статей в формате _.csv_ (_paper_titles.csv_) [ссылка на данные](https://drive.google.com/drive/folders/1Icl9RaCK_5z3m8Ku3O9Imt2QYffH2a89?usp=sharing);
* в командной строке меняется директория на заданную (_cd your/directory_);
* при первом запуске необходимо сначала обучить модель с помощью функции _fit_ и переданным аргументом - название файла с исходными данными (в данном случае, _paper_titles.csv_) (_python ig_nobel.py fit paper_titles.csv_);
* при втором и последующих запусках следует вызывать функцию _run_ и передавать аргумент - произвольное первое слово для названия статьи на английском языке (например, _python ig_nobel.py run interstellar_). Генерация названия занимает около 15 секунд.
* модель обучается на данных статей из STEM (Science, Technology, Engineering, Mathematics) областей, поэтому целесообразно вводить слова из этих областей. В случае ввода произвольных слов логика выданного текста может удивлять :)

### или кратко:
_python ig_nobel.py fit paper_titles.csv_ - обучить модель;
_python ig_nobel.py run space_ - запустить генерацию названия.

Программа написана на Python 3.7; данные представлены на английском языке.

В качестве исходных данных использован датасет с названиями научных статей ([STEM-тематика](https://www.kaggle.com/Cornell-University/arxiv)) (S-science (наука), T-technology (технология), Е-engineering (инженерия), М-mathematics (математика)), а также датасет со статьями по медицине ([Kaggle](https://www.kaggle.com/Cornell-University/arxiv)). Поскольку данные представлены в избыточном и сыром виде, проведена предобработка: выделены только названия статей, отфильтрованы аббревиатуры и узко-специализированные сокращения. В результате использовано 1.771.038 статей.

Генератор реализован на основе триграммной модели ([источник](https://habr.com/ru/post/88514/)). Представленная в статье модель была доработана следующим образом:
* добавлен выбор первого слова;
* в случае отсутствия слова в корпусе - поиск ближайшего к нему по расстоянию Левенштейна;
* улучшена рандомизация (каждое следующее слово, начиная со второго, выбирается случайным образом из представленных в модели пар (слово, вероятность) на основании предыдущего);
* добавлен интерфейс.

### Принцип работы:
Весь скрипт логически поделен на 3 основные части:
1. Подготовка данных для составления модели. Сначала из исходного корпуса (названия статей) формируется генератор текста ( функция _gen_lines_). Затем форимируются генератор токенов (функция _gen_tokens_) - выдает очищенную полседовательность слов и знаков препинания и генератор триграмм (_gen_trigrams_) - тройки идущих подряд токенов. 
Символы _'$'_ используются для маркировки начала предложения. В целом, генератор триграмм действует следующим образом: он возвращает три подряд идущих токена, на каждой итерации сдвигаясь на один токен.
2. Составление (обучение) модели (функция _train_). В этой функции вычисляется вероятность слова в зависимости от двух предыдущих; каждое слово и его вероятность помещается в словарь (модель). С программной точки зрения, модель (_model_) представляет собой список, в котором для каждой пары слов содержится список пар (слово, вероятность).
3. Генерация названий (функция _gen_title_). Первое слово задается вручную через CLI. В случае, если заданное слово отсутствует в модели, с помощью метода _process.extract_ из библиотеки fuzzywuzzy, основанного на расчете расстояния Левенштейна, подбирается случайное слово из пяти наиболее близких к нему по значению. Каждое последующее слово выбирается случайным образом из модели (функция _unirand_) на основании предыдущего слова. Длина названия искусственно ограничена сверху (100 символов). 

### Идеи по улучшению (пространство для творчества):
* улучшенная рандомизация (подбирается индивидуально под каждую задачу);
* разнообразие данных (модель обучена и работает со STEM-дисциплинами);
* улучшенное быстродействие (за счет применения более изысканных алгоритмов).

Пример использования основного функционала Вы можете найти в ноутбуке _Ig_Nobel_Prize.ipynb_

* Автор скрипта - Александр Мирленко
* Поиск данных - Владимир Семериков, Ирина Васильева, Сергей Мельник
* Ментор - Анастасия Малышева



